{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trail_images = np.zeros((2,224,224,3))\n",
    "trail_images[0] = image.array_to_img(image.load_img('trail_images/1_1.jpg'))\n",
    "trail_images[1] = image.array_to_img(image.load_img('trail_images/1_2.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading Model\n",
    "Note: that this model can be reproduced by using keras.applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embs = model.predict(trail_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.66334650e-03,   8.14079523e-01,   1.11252833e-02,\n",
       "         2.49515414e+00,   0.00000000e+00,   3.12298119e-01,\n",
       "         6.72828734e-01,   7.97079504e-03,   6.85831726e-01,\n",
       "         3.83406967e-01,   4.52610105e-01,   1.46672547e-01,\n",
       "         4.70056646e-02,   0.00000000e+00,   9.05495882e-01,\n",
       "         1.57297403e-01,   0.00000000e+00,   3.85352746e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.68608144e-01,\n",
       "         6.64086103e-01,   1.68223426e-01,   6.17932156e-02,\n",
       "         1.90472916e-01,   6.45114839e-01,   2.05633402e-01,\n",
       "         3.38879903e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   7.08613753e-01,   0.00000000e+00,\n",
       "         3.12051475e-01,   3.45117673e-02,   5.24696767e-01,\n",
       "         7.75095373e-02,   1.47262895e+00,   6.24355301e-02,\n",
       "         3.28966618e-01,   0.00000000e+00,   2.90383071e-01,\n",
       "         3.04302797e-02,   0.00000000e+00,   1.86312780e-01,\n",
       "         9.55196992e-02,   1.34004414e+00,   4.61207666e-02,\n",
       "         6.22883327e-02,   9.93242562e-02,   2.76784509e-01,\n",
       "         1.04781485e+00,   9.69530828e-03,   1.04441988e+00,\n",
       "         0.00000000e+00,   3.35550725e-01,   0.00000000e+00,\n",
       "         1.17608380e+00,   3.48903239e-01,   2.25505129e-01,\n",
       "         1.84865522e+00,   2.65169322e-01,   1.09469838e-01,\n",
       "         3.00239712e-01,   9.46304917e-01,   7.55283684e-02,\n",
       "         2.75212228e-01,   3.62722546e-01,   7.52307028e-02,\n",
       "         1.30524151e-02,   5.76089360e-02,   4.59683120e-01,\n",
       "         3.54292803e-02,   0.00000000e+00,   5.84913127e-04,\n",
       "         1.02955353e+00,   2.27273941e-01,   3.51114362e-01,\n",
       "         6.38897344e-03,   2.11438134e-01,   7.31326520e-01,\n",
       "         0.00000000e+00,   9.58013535e-02,   0.00000000e+00,\n",
       "         5.68300068e-01,   2.00528000e-02,   6.58516362e-02,\n",
       "         6.00108579e-02,   3.84215206e-01,   8.94996226e-01,\n",
       "         4.19848531e-01,   2.42410734e-01,   1.06009521e-01,\n",
       "         0.00000000e+00,   2.18903601e-01,   0.00000000e+00,\n",
       "         9.84474003e-01,   7.71767497e-01,   2.00094372e-01,\n",
       "         1.26405835e+00], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = embs.squeeze()\n",
    "embs[0][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Trying preprocessing as suggested\n",
    "function is taken from keras.applications.imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x, data_format=None, mode='caffe'):\n",
    "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: input Numpy tensor, 4D.\n",
    "        data_format: data format of the image tensor.\n",
    "        mode: One of \"caffe\", \"tf\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling.\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "    # Returns\n",
    "        Preprocessed tensor.\n",
    "    \"\"\"\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if mode == 'tf':\n",
    "        x /= 255.\n",
    "        x -= 0.5\n",
    "        x *= 2.\n",
    "        return x\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            # 'RGB'->'BGR'\n",
    "            x = x[::-1, ...]\n",
    "            # Zero-center by mean pixel\n",
    "            x[0, :, :] -= 103.939\n",
    "            x[1, :, :] -= 116.779\n",
    "            x[2, :, :] -= 123.68\n",
    "        else:\n",
    "            x = x[:, ::-1, ...]\n",
    "            x[:, 0, :, :] -= 103.939\n",
    "            x[:, 1, :, :] -= 116.779\n",
    "            x[:, 2, :, :] -= 123.68\n",
    "    else:\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[..., ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trail_images2 = np.zeros((2,224,224,3))\n",
    "trail_images2[0] = preprocess_input(trail_images[0])\n",
    "trail_images2[1] = preprocess_input(trail_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   8.32485974e-01,   3.57342176e-02,\n",
       "         4.71976566e+00,   0.00000000e+00,   5.01036346e-01,\n",
       "         1.13746357e+00,   6.80260267e-03,   9.69435394e-01,\n",
       "         4.02510881e-01,   4.25002337e-01,   3.68344635e-01,\n",
       "         2.59720478e-02,   0.00000000e+00,   1.33642220e+00,\n",
       "         2.89050162e-01,   0.00000000e+00,   4.08360541e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.13491070e-01,\n",
       "         4.54705149e-01,   2.63358951e-01,   2.11133048e-01,\n",
       "         1.45672426e-01,   6.45071208e-01,   1.04144223e-01,\n",
       "         0.00000000e+00,   2.83974390e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.93708535e-02,   7.18003809e-02,\n",
       "         5.55889249e-01,   0.00000000e+00,   1.41675577e-01,\n",
       "         0.00000000e+00,   3.90557081e-01,   3.26747745e-01,\n",
       "         1.08520162e+00,   3.87041643e-02,   5.27665019e-01,\n",
       "         2.10631755e-03,   6.59319460e-02,   0.00000000e+00,\n",
       "         6.59667403e-02,   7.80317008e-01,   0.00000000e+00,\n",
       "         1.19890064e-01,   2.46666834e-01,   1.50973976e-01,\n",
       "         2.26778460e+00,   7.44291902e-01,   2.48989701e+00,\n",
       "         0.00000000e+00,   1.50655434e-01,   3.29779251e-03,\n",
       "         7.36084461e-01,   7.15384901e-01,   6.28796592e-02,\n",
       "         2.46770167e+00,   1.23534478e-01,   3.77291404e-02,\n",
       "         4.81198341e-01,   6.22934222e-01,   0.00000000e+00,\n",
       "         2.79755950e-01,   5.95617115e-01,   2.50329170e-02,\n",
       "         1.63274873e-02,   5.86442323e-03,   1.04628301e+00,\n",
       "         1.83829561e-01,   2.12073866e-02,   0.00000000e+00,\n",
       "         4.63672638e-01,   9.55312774e-02,   7.60062695e-01,\n",
       "         2.09878176e-03,   5.09208813e-02,   3.59786332e-01,\n",
       "         0.00000000e+00,   1.89998984e-01,   0.00000000e+00,\n",
       "         9.69636559e-01,   0.00000000e+00,   1.66485682e-01,\n",
       "         1.85356915e-01,   3.43211144e-01,   3.62723410e-01,\n",
       "         7.88056999e-02,   8.81896913e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   6.23183101e-02,\n",
       "         4.28220868e-01,   9.52541590e-01,   4.17690910e-02,\n",
       "         1.53590739e+00], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs2 = model.predict(trail_images2)\n",
    "embs2 = embs2.squeeze()\n",
    "embs2[0][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now trying with preprocessing mode = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trail_images3 = np.zeros((2,224,224,3))\n",
    "trail_images3[0] = preprocess_input(trail_images[0],mode=\"tf\")\n",
    "trail_images3[1] = preprocess_input(trail_images[1],mode=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   4.12747310e-03,\n",
       "         0.00000000e+00,   5.50312817e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   7.26377189e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.85149217e-01,\n",
       "         1.47083094e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.65573051e-03,   0.00000000e+00,\n",
       "         9.32822097e-03,   6.06841087e-01,   0.00000000e+00,\n",
       "         4.87885140e-02,   0.00000000e+00,   2.54396768e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.25301848e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.38765225e-02,\n",
       "         0.00000000e+00,   5.33546805e-02,   1.28633052e-01,\n",
       "         0.00000000e+00,   2.07603700e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.37142983e-04,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.72073650e+00,   7.23731458e-01,   5.30588925e-02,\n",
       "         0.00000000e+00,   2.94060893e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.21365526e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.11428984e-02,   7.97654409e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.98096319e-03,   1.51952669e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.56443764e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.00480378e-01,   2.24353578e-02,\n",
       "         0.00000000e+00,   1.79275367e-02,   0.00000000e+00,\n",
       "         2.03894719e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.81728047e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs3 = model.predict(trail_images3)\n",
    "embs3 = embs3.squeeze()\n",
    "embs3[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
